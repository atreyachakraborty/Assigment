{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891d6a0a-cbee-4ae1-8c66-c07ee7b11478",
   "metadata": {},
   "source": [
    "1. What is Simple Linear Regression?\n",
    "Simple Linear Regression is a statistical method used to model the relationship between two continuous variables: one independent variable (X) and one dependent variable (Y). The goal is to find a linear equation that best fits the data, typically in the form:\n",
    "[ Y = mX + c ]\n",
    "where m is the slope and c is the intercept.\n",
    "\n",
    "\n",
    "2. What are the key assumptions of Simple Linear Regression?\n",
    "- Linearity: The relationship between X and Y is linear.\n",
    "- Independence: Observations are independent of each other.\n",
    "- Homoscedasticity: The variance of residuals is constant across all levels of X.\n",
    "- Normality of Errors: Residuals (errors) should be normally distributed.\n",
    "- No Perfect Multicollinearity: Only one independent variable is present, avoiding collinearity issues.\n",
    "\n",
    "\n",
    "3. What does the coefficient m represent in the equation (Y = mX + c)?\n",
    "m (slope) represents the rate of change in Y for a one-unit increase in X. It quantifies how much the dependent variable changes for every unit increase in the independent variable.\n",
    "\n",
    "\n",
    "4. What does the intercept c represent in the equation (Y = mX + c)?\n",
    "c is the value of Y when X = 0. It represents the starting point or baseline of the relationship in the absence of any influence from X.\n",
    "\n",
    "\n",
    "5. How do we calculate the slope m in Simple Linear Regression?\n",
    "The slope is calculated using:\n",
    "[ m = \\frac{\\sum (X_i - \\bar{X}) (Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2} ]\n",
    "where X̄ and Ȳ are the mean values of X and Y, respectively.\n",
    "\n",
    "\n",
    "7. What is the purpose of the least squares method in Simple Linear Regression?\n",
    "The Least Squares Method minimizes the sum of squared residuals (differences between actual and predicted values) to find the best-fitting line.\n",
    "\n",
    "\n",
    "8. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?\n",
    "( R^2 ) measures how well the model explains variability in Y.\n",
    "- ( R^2 = 1 ) → Perfect fit\n",
    "- ( R^2 = 0 ) → No relationship\n",
    "\n",
    "\n",
    "8. What is Multiple Linear Regression?\n",
    "Multiple Linear Regression extends Simple Linear Regression by using multiple independent variables to predict a dependent variable:\n",
    "[ Y = b_0 + b_1X_1 + b_2X_2 + ... + b_nX_n ]\n",
    "\n",
    "\n",
    "9. What is the main difference between Simple and Multiple Linear Regression?\n",
    "- Simple Linear Regression: One independent variable.\n",
    "- Multiple Linear Regression: Two or more independent variables.\n",
    "\n",
    "\n",
    "10. What are the key assumptions of Multiple Linear Regression?\n",
    "- Linearity\n",
    "- Independence\n",
    "- Homoscedasticity\n",
    "- Normality of errors\n",
    "- No multicollinearity\n",
    "\n",
    "\n",
    "11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
    "Heteroscedasticity occurs when residuals' variance is not constant, making predictions less reliable. It may indicate model misspecification.\n",
    "\n",
    "\n",
    "12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
    "- Remove highly correlated predictors\n",
    "- Use Principal Component Analysis (PCA)\n",
    "- Apply Ridge or Lasso Regression\n",
    "\n",
    "\n",
    "13. What are some common techniques for transforming categorical variables for use in regression models?\n",
    "- One-Hot Encoding\n",
    "- Label Encoding\n",
    "- Dummy Variables\n",
    "\n",
    "\n",
    "14. What is the role of interaction terms in Multiple Linear Regression?\n",
    "Interaction terms capture effects when two independent variables influence the dependent variable jointly.\n",
    "\n",
    "\n",
    "15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
    "In Simple Linear Regression, the intercept represents Y when X = 0.\n",
    "In Multiple Linear Regression, the intercept represents Y when all predictors are set to zero.\n",
    "\n",
    "\n",
    "16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
    "The slope indicates how much Y changes when a predictor increases by one unit.\n",
    "\n",
    "\n",
    "17. How does the intercept in a regression model provide context for the relationship between variables?\n",
    "The intercept serves as a baseline value of Y when all independent variables are zero.\n",
    "\n",
    "\n",
    "18. What are the limitations of using R² as a sole measure of model performance?\n",
    "- It does not indicate causality.\n",
    "- It cannot detect model overfitting.\n",
    "- It does not tell if coefficients are statistically significant.\n",
    "\n",
    "\n",
    "19. How would you interpret a large standard error for a regression coefficient?\n",
    "It suggests uncertainty in the estimated coefficient, making predictions less reliable.\n",
    "\n",
    "\n",
    "20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
    "Look for a funnel-shaped pattern in residual plots. Addressing it ensures consistent variance assumptions hold.\n",
    "\n",
    "\n",
    "21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
    "It indicates too many predictors, possibly causing overfitting.\n",
    "\n",
    "\n",
    "22. Why is it important to scale variables in Multiple Linear Regression?\n",
    "Scaling prevents large magnitude differences from dominating the regression.\n",
    "\n",
    "\n",
    "23. What is polynomial regression?\n",
    "Polynomial regression extends linear regression by modeling curved relationships:\n",
    "[ Y = b_0 + b_1X + b_2Xn ]\n",
    "\n",
    "\n",
    "24. How does polynomial regression differ from linear regression?\n",
    "Linear regression models straight-line relationships.\n",
    "Polynomial regression captures non-linear trends.\n",
    "\n",
    "\n",
    "25. When is polynomial regression used?\n",
    "When data exhibits a curved relationship.\n",
    "\n",
    "\n",
    "26. What is the general equation for polynomial regression?\n",
    "[ Y = b_0 + b_1X + b_2Xn ]\n",
    "\n",
    "27. Can polynomial regression be applied to multiple variables?\n",
    "Yes, it can include interaction terms for multiple predictors.\n",
    "\n",
    "28. What are the limitations of polynomial regression?\n",
    "- Overfitting risk\n",
    "- Higher complexity\n",
    "- Interpolation issues\n",
    "\n",
    "\n",
    "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
    "- R² score\n",
    "- Cross-validation\n",
    "- Residual plots\n",
    "\n",
    "\n",
    "30. Why is visualization important in polynomial regression?\n",
    "It helps detect patterns, overfitting, and relationships in the data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e22851-fea5-4022-948c-ba1ad0b0c1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.2]\n"
     ]
    }
   ],
   "source": [
    "# 31. How is polynomial regression implemented in Python?\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "X = [[1], [2], [3], [4], [5]]\n",
    "y = [2, 3, 5, 7, 11]\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "model.fit(X, y)\n",
    "print(model.predict([[6]]))  # Predict for X=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4689f9-2a12-4bcb-a829-2ec19381539a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
