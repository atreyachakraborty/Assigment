{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0530a61-fd5d-4db0-88fc-5fd5c6e3a75a",
   "metadata": {},
   "source": [
    "Theoretical----\n",
    "\n",
    "# 1.What is a Decision Tree, and how does it work?\n",
    "A Decision Tree is a flowchart-like structure used for decision-making and classification. It splits data into branches based on feature values. Each internal node represents a test on an attribute, each branch represents the test outcome, and each leaf node represents a class label or decision. The tree structure helps make decisions by traversing from the root to a leaf based on feature values.\n",
    "\n",
    "# 2.What are impurity measures in Decision Trees?\n",
    "Impurity measures are used to determine how mixed the data is at a node. The goal is to find the split that results in the highest information gain, or equivalently, the lowest impurity. The two most common impurity measures are Gini Impurity and Entropy.\n",
    "\n",
    "# 3.What is the mathematical formula for Gini Impurity?\n",
    "The Gini Impurity for a node is calculated as: \n",
    "##Gini = 1 - sumation_{i=1}^{n} p_i^2 $$ where \n",
    "ùëù ùëñ is the probability of class ùëñ in the node.\n",
    "\n",
    "\n",
    "# 4.What is the mathematical formula for Entropy?\n",
    "The Entropy for a node is calculated as: \n",
    "##Entropy = -sumation_{i=1}^{n} p_i \\log_2(p_i)\n",
    "where ùëù ùëñ is the probability of class ùëñ in the node.\n",
    "\n",
    "\n",
    "# 5.What is Information Gain, and how is it used in Decision Trees?\n",
    "Information Gain is the reduction in entropy or impurity after a dataset is split on an attribute. It is used to determine the best attribute for splitting the data. Information Gain is calculated as the difference between the entropy of the parent node and the weighted sum of the entropy of the child nodes.\n",
    "\n",
    "\n",
    "# 6.What is the difference between Gini Impurity and Entropy?\n",
    "Both Gini Impurity and Entropy measure the impurity of a node, but they are calculated differently. Gini Impurity is simpler and computationally less intensive, while Entropy provides a more information-theoretic measure. In practice, they often lead to similar results.\n",
    "\n",
    "\n",
    "# 7.What is the mathematical explanation behind Decision Trees?\n",
    "Decision Trees use a recursive algorithm called ‚Äúrecursive binary splitting‚Äù to partition the data into subsets based on attribute values. The algorithm continues to split the data until it reaches a stopping criterion, such as a maximum tree depth or a minimum number of samples per node.\n",
    "\n",
    "# 8.What is Pre-Pruning in Decision Trees?\n",
    "Pre-Pruning (also known as early stopping) involves halting the tree-building process before it becomes too complex. This can be done by setting constraints such as maximum depth, minimum samples per split, or minimum samples per leaf.\n",
    "\n",
    "# 9.What is Post-Pruning in Decision Trees?\n",
    "Post-Pruning involves growing a full tree and then removing branches that have little importance or contribute to overfitting. Techniques like Reduced Error Pruning or Cost Complexity Pruning can be used to trim the tree.\n",
    "\n",
    "# 10.What is the difference between Pre-Pruning and Post-Pruning?\n",
    "The key difference is the timing. Pre-Pruning stops the tree from growing beyond a certain point, preventing complexity during tree construction. Post-Pruning allows the tree to grow fully and then simplifies it by removing branches.\n",
    "\n",
    "# 11.What is a Decision Tree Regressor?\n",
    "A Decision Tree Regressor is used for regression tasks. Instead of predicting a class label, it predicts a continuous value. The structure is similar to a Decision Tree Classifier, but the leaves contain mean values of the target variable.\n",
    "\n",
    "# 12.What are the advantages and disadvantages of Decision Trees?\n",
    "Advantages:\n",
    "\n",
    "Easy to understand and interpret\n",
    "Requires little data preprocessing\n",
    "Handles both numerical and categorical data\n",
    "Non-parametric, making it flexible to various data distributions\n",
    "\n",
    "Disadvantages:\n",
    "Prone to overfitting, especially with deep trees\n",
    "Sensitive to noisy data and small variations\n",
    "Can be biased with imbalanced datasets\n",
    "\n",
    "\n",
    "# 13.How does a Decision Tree handle missing values?\n",
    "Decision Trees can handle missing values by using surrogate splits, which use alternative features to make splits when the primary feature is missing. Some implementations also allow for imputation of missing values.\n",
    "\n",
    "# 14.How does a Decision Tree handle categorical features?\n",
    "Categorical features are handled by creating separate branches for each category. For large categorical features, some implementations use grouping or encoding techniques to manage the splits effectively.\n",
    "\n",
    "# 15.What are some real-world applications of Decision Trees?\n",
    "Medical Diagnosis: Decision Trees can help in diagnosing diseases based on patient data.\n",
    "\n",
    "Financial Analysis: Used for credit scoring and risk management.\n",
    "\n",
    "Customer Relationship Management: Helps in customer segmentation and targeting.\n",
    "\n",
    "Fraud Detection: Identifies patterns indicative of fraudulent activities.\n",
    "\n",
    "Market Research: Assists in understanding consumer preferences and behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee064287-acb6-46ae-b253-4410c8a5ab42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fb0a57-6a37-4268-88bf-928f10cc988b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f4c2148-065a-49d6-afd6-05d1bda69cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy?\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "data=load_iris()\n",
    "\n",
    "X,y=data.data,data.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "clf=DecisionTreeClassifier()\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb80367-f08e-4ef8-8307-3f05be6dd0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b62bbc5-0fba-4714-adde-d1a284f0b4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc650c4f-ca0f-41f3-97f2-ff2bf36a17cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sepal width (cm)</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sepal length (cm)</td>\n",
       "      <td>0.038220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>0.404457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petal width (cm)</td>\n",
       "      <td>0.557323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  importance\n",
       "1   sepal width (cm)    0.000000\n",
       "0  sepal length (cm)    0.038220\n",
       "2  petal length (cm)    0.404457\n",
       "3   petal width (cm)    0.557323"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 17. Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the \n",
    "#feature importances\n",
    "\n",
    "data=load_iris()\n",
    "\n",
    "X,y=data.data,data.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "clf=DecisionTreeClassifier()\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "feature_importance=clf.feature_importances_\n",
    "feature_names=data.feature_names\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    \"feature\":feature_names,\n",
    "    \"importance\":feature_importance\n",
    "}).sort_values(by=\"importance\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c70435-6e52-4fda-b9d0-f27eff5e020b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c85e7dc-1819-40ae-b327-703a2fb9670c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c459ac11-c004-4c2c-a37d-f80168eb6278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.935672514619883\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean concave points</td>\n",
       "      <td>0.736488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>worst texture</td>\n",
       "      <td>0.105480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>worst radius</td>\n",
       "      <td>0.039537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>worst area</td>\n",
       "      <td>0.036653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean texture</td>\n",
       "      <td>0.022885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>worst fractal dimension</td>\n",
       "      <td>0.017164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area error</td>\n",
       "      <td>0.013563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>worst smoothness</td>\n",
       "      <td>0.010492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>worst concave points</td>\n",
       "      <td>0.008582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mean symmetry</td>\n",
       "      <td>0.007152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>smoothness error</td>\n",
       "      <td>0.002004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>worst perimeter</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>symmetry error</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>worst compactness</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>worst concavity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>worst symmetry</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fractal dimension error</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean radius</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points error</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concavity error</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>perimeter error</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texture error</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>radius error</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mean fractal dimension</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean concavity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean compactness</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean smoothness</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean area</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean perimeter</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness error</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  importance\n",
       "7       mean concave points    0.736488\n",
       "21            worst texture    0.105480\n",
       "20             worst radius    0.039537\n",
       "23               worst area    0.036653\n",
       "1              mean texture    0.022885\n",
       "29  worst fractal dimension    0.017164\n",
       "13               area error    0.013563\n",
       "24         worst smoothness    0.010492\n",
       "27     worst concave points    0.008582\n",
       "8             mean symmetry    0.007152\n",
       "14         smoothness error    0.002004\n",
       "22          worst perimeter    0.000000\n",
       "18           symmetry error    0.000000\n",
       "25        worst compactness    0.000000\n",
       "26          worst concavity    0.000000\n",
       "28           worst symmetry    0.000000\n",
       "19  fractal dimension error    0.000000\n",
       "0               mean radius    0.000000\n",
       "17     concave points error    0.000000\n",
       "16          concavity error    0.000000\n",
       "12          perimeter error    0.000000\n",
       "11            texture error    0.000000\n",
       "10             radius error    0.000000\n",
       "9    mean fractal dimension    0.000000\n",
       "6            mean concavity    0.000000\n",
       "5          mean compactness    0.000000\n",
       "4           mean smoothness    0.000000\n",
       "3                 mean area    0.000000\n",
       "2            mean perimeter    0.000000\n",
       "15        compactness error    0.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#18. Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the \n",
    "#model accuracy\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data=load_breast_cancer()\n",
    "\n",
    "X,y=data.data,data.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "clf=DecisionTreeClassifier()\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "print(\"accuracy score:\", accuracy_score(y_test,y_pred))\n",
    "\n",
    "feature_importance=clf.feature_importances_\n",
    "feature_names=data.feature_names\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    \"feature\":feature_names,\n",
    "    \"importance\":feature_importance\n",
    "}).sort_values(by=\"importance\",ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1179ebd-ad79-4ce4-849b-d39e630cd7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0efd38-2294-4610-9373-dbe937264ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa8de205-7d6a-4f1e-87b7-af62b84aee52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.532928536351292"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#19. Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean \n",
    "#Squared Error (MSE)\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data=fetch_california_housing()\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model=DecisionTreeRegressor()\n",
    "\n",
    "X=data.data\n",
    "y=data.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30,random_state=42)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a082d-0206-46c0-ac5e-22850f0a4dce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e8ad20-fdb5-4f77-983d-61065c1e0eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de2854f-4895-4b5b-a5a8-6e450b633983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.567419678079617\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#20. Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data=fetch_california_housing()\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model=DecisionTreeRegressor(max_depth=4)\n",
    "\n",
    "X=data.data\n",
    "y=data.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30,random_state=42)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "from sklearn import tree\n",
    "tree.plot_tree(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f686d-8ffe-447a-999b-4a3097bf2d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6a165-bfb5-4e0d-99aa-9e967b536406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bf7b60b-10ad-41a9-9113-ca7b0e6b0c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score for depth max 0.9629629629629629\n",
      "accuracy score for depth 3 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "#21. Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its \n",
    "#accuracy with a fully grown \n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "data=load_wine()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model=DecisionTreeClassifier()\n",
    "\n",
    "X=data.data\n",
    "y=data.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30,random_state=42)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "print(f\"accuracy score for depth max { accuracy_score(y_test,y_pred)}\")\n",
    "\n",
    "\n",
    "\n",
    "model2=DecisionTreeClassifier(max_depth=3)\n",
    "model2.fit(X_train,y_train)\n",
    "y_pred2=model2.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"accuracy score for depth 3 {accuracy_score(y_test,y_pred2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91781f6-fb1c-4a13-a410-3582f68e29e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34ac1ce-243b-486c-8030-538fb767cc49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bb1b9c3-00de-49d7-a446-1a0dabe9fbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score for depth max 0.935672514619883\n",
      "accuracy score for min sample split 5 0.935672514619883\n"
     ]
    }
   ],
   "source": [
    "#22 Write a Python program to train a Decision Tree Classifier using min_samples_split=5 and compare its \n",
    "#accuracy with a default tree\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data=load_breast_cancer()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model=DecisionTreeClassifier()\n",
    "\n",
    "X=data.data\n",
    "y=data.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30,random_state=42)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "print(f\"accuracy score for depth max { accuracy_score(y_test,y_pred)}\")\n",
    "\n",
    "\n",
    "\n",
    "model2=DecisionTreeClassifier(min_samples_split=5) #The minimum number of samples required to split an internal node:\n",
    "model2.fit(X_train,y_train)\n",
    "y_pred2=model2.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"accuracy score for min sample split 5 {accuracy_score(y_test,y_pred2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe265acd-4c36-46bf-ad5b-93e3983a796a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17456a50-7a31-4e0e-9a23-3058f71dbfea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee4e4e25-7d1a-44b4-bdc6-111df02c040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score for non-scaled data0.8518518518518519\n",
      "accuracy score for scaled data 0.8555555555555555\n"
     ]
    }
   ],
   "source": [
    "#23. Write a Python program to apply feature scaling before training a Decision Tree Classifier and compare its \n",
    "#accuracy with unscaled data\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data=load_digits()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model=DecisionTreeClassifier()\n",
    "\n",
    "X=data.data\n",
    "y=data.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30,random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "\n",
    "X_train_scale=scaler.fit_transform(X_train)\n",
    "X_test_scale=scaler.transform(X_test)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "print(f\"accuracy score for non-scaled data{ accuracy_score(y_test,y_pred)}\")\n",
    "\n",
    "\n",
    "\n",
    "model2=DecisionTreeClassifier() #The minimum number of samples required to split an internal node:\n",
    "model2.fit(X_train_scale,y_train)\n",
    "y_pred2=model2.predict(X_test_scale)\n",
    "\n",
    "\n",
    "print(f\"accuracy score for scaled data {accuracy_score(y_test,y_pred2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d511ce-7c7a-4baa-a48d-f581310a2c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f48619-f699-44e6-898c-8e8c3850ecb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21374f69-a902-49ce-a1a6-aaca950d1f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree Classifier using One-vs-Rest strategy: 0.85\n"
     ]
    }
   ],
   "source": [
    "#24. Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass \n",
    "#classification\n",
    "\n",
    "\n",
    "load_digits = load_digits()\n",
    "X, y = load_digits.data, load_digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Training a Decision Tree Classifier using One-vs-Rest strategy\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "clf = OneVsRestClassifier(DecisionTreeClassifier(random_state=42))\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy of Decision Tree Classifier using One-vs-Rest strategy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fed7315-fe0d-42b1-9352-bed52e076687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f93e1-d8c2-414e-9a40-42bba4557d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37836984-b9f5-439a-8f8a-ab7b1e588e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>feature_inportance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean radius</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>worst concave points</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>worst concavity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>worst compactness</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>worst perimeter</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fractal dimension error</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>symmetry error</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points error</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concavity error</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness error</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area error</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>perimeter error</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>worst fractal dimension</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mean fractal dimension</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mean symmetry</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean perimeter</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean concavity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean compactness</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean area</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean smoothness</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>smoothness error</td>\n",
       "      <td>0.002004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>worst symmetry</td>\n",
       "      <td>0.007152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>worst smoothness</td>\n",
       "      <td>0.010492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>radius error</td>\n",
       "      <td>0.013563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texture error</td>\n",
       "      <td>0.017164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean texture</td>\n",
       "      <td>0.022885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>worst area</td>\n",
       "      <td>0.036653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>worst radius</td>\n",
       "      <td>0.078769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>worst texture</td>\n",
       "      <td>0.105480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean concave points</td>\n",
       "      <td>0.705839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature_name  feature_inportance\n",
       "0               mean radius            0.000000\n",
       "27     worst concave points            0.000000\n",
       "26          worst concavity            0.000000\n",
       "25        worst compactness            0.000000\n",
       "22          worst perimeter            0.000000\n",
       "19  fractal dimension error            0.000000\n",
       "18           symmetry error            0.000000\n",
       "17     concave points error            0.000000\n",
       "16          concavity error            0.000000\n",
       "15        compactness error            0.000000\n",
       "13               area error            0.000000\n",
       "12          perimeter error            0.000000\n",
       "29  worst fractal dimension            0.000000\n",
       "9    mean fractal dimension            0.000000\n",
       "8             mean symmetry            0.000000\n",
       "2            mean perimeter            0.000000\n",
       "6            mean concavity            0.000000\n",
       "5          mean compactness            0.000000\n",
       "3                 mean area            0.000000\n",
       "4           mean smoothness            0.000000\n",
       "14         smoothness error            0.002004\n",
       "28           worst symmetry            0.007152\n",
       "24         worst smoothness            0.010492\n",
       "10             radius error            0.013563\n",
       "11            texture error            0.017164\n",
       "1              mean texture            0.022885\n",
       "23               worst area            0.036653\n",
       "20             worst radius            0.078769\n",
       "21            worst texture            0.105480\n",
       "7       mean concave points            0.705839"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#25.Write a Python program to train a Decision Tree Classifier and display the feature importance scores\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data=load_breast_cancer()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model=DecisionTreeClassifier()\n",
    "\n",
    "X=data.data\n",
    "y=data.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30,random_state=42)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "feature=model.feature_importances_\n",
    "feature_name=data.feature_names\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    \"feature_name\":feature_name,\n",
    "                \"feature_inportance\":feature}).sort_values(by=\"feature_inportance\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab35bdc-0e9a-4c87-ae11-f1c01897fd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40405dd-867d-481e-b628-9fa2c3b54b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb5f6159-50fd-4543-b20e-fefc02590a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score for depth max 0.8388888888888889\n",
      "accuracy score for depth 5 0.6648148148148149\n"
     ]
    }
   ],
   "source": [
    "#26. Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance \n",
    "#with an unrestricted tree\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data=load_digits()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model=DecisionTreeClassifier()\n",
    "\n",
    "X=data.data\n",
    "y=data.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30,random_state=42)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "print(f\"accuracy score for depth max { accuracy_score(y_test,y_pred)}\")\n",
    "\n",
    "\n",
    "\n",
    "model2=DecisionTreeClassifier(max_depth=5)\n",
    "model2.fit(X_train,y_train)\n",
    "y_pred2=model2.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"accuracy score for depth 5 {accuracy_score(y_test,y_pred2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0b5a2e-c777-42a3-b7b3-fc0029168cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60462682-7e0d-4212-af43-21c3cb74dece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8921e74b-0ca1-468e-9d98-dd667a8130fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score for depth max 0.8537037037037037\n",
      "accuracy score for ccp of 5.555 0.09259259259259259\n"
     ]
    }
   ],
   "source": [
    "#27. Write a Python program to train a Decision Tree Classifier, apply Cost Complexity Pruning (CCP), and \n",
    "#visualize its effect on accuracy\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data=load_digits()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model=DecisionTreeClassifier()\n",
    "\n",
    "X=data.data\n",
    "y=data.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30,random_state=42)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "print(f\"accuracy score for depth max { accuracy_score(y_test,y_pred)}\")\n",
    "\n",
    "\n",
    "\n",
    "model2=DecisionTreeClassifier(ccp_alpha=5.555)\n",
    "model2.fit(X_train,y_train)\n",
    "y_pred2=model2.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"accuracy score for ccp of 5.555 {accuracy_score(y_test,y_pred2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b09d89-bb31-44c9-a1ed-299ac363fb92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e264a9-e316-4454-b22e-ec0e8cce9b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7b3a76d-bcda-40ad-b0c8-c833a85f9a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 189 candidates, totalling 378 fits\n",
      "[CV 1/2] END criterion=gini, max_depth=1, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=1, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=1, min_samples_split=2;, score=0.203 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=1, min_samples_split=2;, score=0.202 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=1, min_samples_split=3;, score=0.203 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=1, min_samples_split=3;, score=0.202 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=1, min_samples_split=4;, score=0.203 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=1, min_samples_split=4;, score=0.202 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=1, min_samples_split=5;, score=0.203 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=1, min_samples_split=5;, score=0.202 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=1, min_samples_split=6;, score=0.203 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=1, min_samples_split=6;, score=0.202 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=1, min_samples_split=7;, score=0.203 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=1, min_samples_split=7;, score=0.202 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, min_samples_split=2;, score=0.677 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, min_samples_split=2;, score=0.694 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, min_samples_split=3;, score=0.682 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, min_samples_split=3;, score=0.688 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, min_samples_split=4;, score=0.671 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, min_samples_split=4;, score=0.691 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, min_samples_split=5;, score=0.682 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, min_samples_split=5;, score=0.688 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, min_samples_split=6;, score=0.682 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, min_samples_split=6;, score=0.686 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, min_samples_split=7;, score=0.679 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, min_samples_split=7;, score=0.688 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=6, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=6, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=6, min_samples_split=2;, score=0.757 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=6, min_samples_split=2;, score=0.740 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=6, min_samples_split=3;, score=0.760 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=6, min_samples_split=3;, score=0.736 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=6, min_samples_split=4;, score=0.750 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=6, min_samples_split=4;, score=0.748 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=6, min_samples_split=5;, score=0.746 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=6, min_samples_split=5;, score=0.753 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=6, min_samples_split=6;, score=0.746 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=6, min_samples_split=6;, score=0.745 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=6, min_samples_split=7;, score=0.762 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=6, min_samples_split=7;, score=0.747 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, min_samples_split=2;, score=0.792 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, min_samples_split=2;, score=0.774 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, min_samples_split=3;, score=0.809 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, min_samples_split=3;, score=0.756 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, min_samples_split=4;, score=0.789 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, min_samples_split=4;, score=0.777 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, min_samples_split=5;, score=0.797 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, min_samples_split=5;, score=0.766 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, min_samples_split=6;, score=0.797 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, min_samples_split=6;, score=0.768 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, min_samples_split=7;, score=0.785 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, min_samples_split=7;, score=0.756 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=8, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=8, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=8, min_samples_split=2;, score=0.797 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=8, min_samples_split=2;, score=0.793 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=8, min_samples_split=3;, score=0.784 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=8, min_samples_split=3;, score=0.782 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=8, min_samples_split=4;, score=0.792 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=8, min_samples_split=4;, score=0.787 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=8, min_samples_split=5;, score=0.790 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=8, min_samples_split=5;, score=0.790 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=8, min_samples_split=6;, score=0.787 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=8, min_samples_split=6;, score=0.790 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=8, min_samples_split=7;, score=0.779 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=8, min_samples_split=7;, score=0.779 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, min_samples_split=2;, score=0.797 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, min_samples_split=2;, score=0.796 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, min_samples_split=3;, score=0.804 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, min_samples_split=3;, score=0.806 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, min_samples_split=4;, score=0.784 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, min_samples_split=4;, score=0.795 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, min_samples_split=5;, score=0.784 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, min_samples_split=5;, score=0.815 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, min_samples_split=6;, score=0.790 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, min_samples_split=6;, score=0.785 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=9, min_samples_split=7;, score=0.777 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=9, min_samples_split=7;, score=0.787 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, min_samples_split=2;, score=0.676 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, min_samples_split=2;, score=0.691 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, min_samples_split=3;, score=0.684 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, min_samples_split=3;, score=0.696 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, min_samples_split=4;, score=0.679 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, min_samples_split=4;, score=0.689 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, min_samples_split=5;, score=0.674 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, min_samples_split=5;, score=0.691 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, min_samples_split=6;, score=0.676 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, min_samples_split=6;, score=0.689 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, min_samples_split=7;, score=0.679 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, min_samples_split=7;, score=0.688 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=10, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=10, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=10, min_samples_split=2;, score=0.792 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=10, min_samples_split=2;, score=0.795 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=10, min_samples_split=3;, score=0.797 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=10, min_samples_split=3;, score=0.793 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=10, min_samples_split=4;, score=0.798 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=10, min_samples_split=4;, score=0.780 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=10, min_samples_split=5;, score=0.798 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=10, min_samples_split=5;, score=0.804 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=10, min_samples_split=6;, score=0.792 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=10, min_samples_split=6;, score=0.775 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=10, min_samples_split=7;, score=0.793 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=10, min_samples_split=7;, score=0.795 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, min_samples_split=2;, score=0.785 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, min_samples_split=2;, score=0.806 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, min_samples_split=3;, score=0.792 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, min_samples_split=3;, score=0.812 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, min_samples_split=4;, score=0.784 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, min_samples_split=4;, score=0.799 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, min_samples_split=5;, score=0.804 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, min_samples_split=5;, score=0.785 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, min_samples_split=6;, score=0.787 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, min_samples_split=6;, score=0.793 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, min_samples_split=7;, score=0.781 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, min_samples_split=7;, score=0.799 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=1, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=1, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=1, min_samples_split=2;, score=0.199 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=1, min_samples_split=2;, score=0.199 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=1, min_samples_split=3;, score=0.199 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=1, min_samples_split=3;, score=0.199 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=1, min_samples_split=4;, score=0.199 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=1, min_samples_split=4;, score=0.199 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=1, min_samples_split=5;, score=0.199 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=1, min_samples_split=5;, score=0.199 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=1, min_samples_split=6;, score=0.199 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=1, min_samples_split=6;, score=0.199 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=1, min_samples_split=7;, score=0.199 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=1, min_samples_split=7;, score=0.199 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, min_samples_split=2;, score=0.704 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, min_samples_split=2;, score=0.818 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, min_samples_split=3;, score=0.709 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, min_samples_split=3;, score=0.814 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, min_samples_split=4;, score=0.709 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, min_samples_split=4;, score=0.811 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, min_samples_split=5;, score=0.712 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, min_samples_split=5;, score=0.814 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, min_samples_split=6;, score=0.706 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, min_samples_split=6;, score=0.811 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, min_samples_split=7;, score=0.712 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, min_samples_split=7;, score=0.818 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=6, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=6, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=6, min_samples_split=2;, score=0.746 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=6, min_samples_split=2;, score=0.823 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=6, min_samples_split=3;, score=0.754 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=6, min_samples_split=3;, score=0.812 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=6, min_samples_split=4;, score=0.744 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=6, min_samples_split=4;, score=0.811 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=6, min_samples_split=5;, score=0.752 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=6, min_samples_split=5;, score=0.831 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=6, min_samples_split=6;, score=0.739 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=6, min_samples_split=6;, score=0.814 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=6, min_samples_split=7;, score=0.744 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=6, min_samples_split=7;, score=0.823 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, min_samples_split=2;, score=0.768 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, min_samples_split=2;, score=0.828 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, min_samples_split=3;, score=0.777 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, min_samples_split=3;, score=0.830 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, min_samples_split=4;, score=0.776 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, min_samples_split=4;, score=0.847 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, min_samples_split=5;, score=0.766 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, min_samples_split=5;, score=0.834 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, min_samples_split=6;, score=0.769 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, min_samples_split=6;, score=0.839 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, min_samples_split=7;, score=0.766 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, min_samples_split=7;, score=0.836 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=8, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=8, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=8, min_samples_split=2;, score=0.789 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=8, min_samples_split=2;, score=0.850 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=8, min_samples_split=3;, score=0.784 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=8, min_samples_split=3;, score=0.836 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=8, min_samples_split=4;, score=0.771 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=8, min_samples_split=4;, score=0.809 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=8, min_samples_split=5;, score=0.782 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=8, min_samples_split=5;, score=0.818 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=8, min_samples_split=6;, score=0.785 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=8, min_samples_split=6;, score=0.831 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=8, min_samples_split=7;, score=0.774 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=8, min_samples_split=7;, score=0.815 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, min_samples_split=2;, score=0.785 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, min_samples_split=2;, score=0.836 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, min_samples_split=3;, score=0.776 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, min_samples_split=3;, score=0.826 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, min_samples_split=4;, score=0.773 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, min_samples_split=4;, score=0.817 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, min_samples_split=5;, score=0.785 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, min_samples_split=5;, score=0.820 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, min_samples_split=6;, score=0.760 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, min_samples_split=6;, score=0.830 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=9, min_samples_split=7;, score=0.779 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=9, min_samples_split=7;, score=0.830 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, min_samples_split=2;, score=0.711 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, min_samples_split=2;, score=0.812 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, min_samples_split=3;, score=0.709 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, min_samples_split=3;, score=0.820 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, min_samples_split=4;, score=0.703 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, min_samples_split=4;, score=0.815 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, min_samples_split=5;, score=0.704 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, min_samples_split=5;, score=0.814 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, min_samples_split=6;, score=0.707 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, min_samples_split=6;, score=0.815 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, min_samples_split=7;, score=0.709 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, min_samples_split=7;, score=0.823 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=10, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=10, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=10, min_samples_split=2;, score=0.785 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=10, min_samples_split=2;, score=0.825 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=10, min_samples_split=3;, score=0.784 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=10, min_samples_split=3;, score=0.839 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=10, min_samples_split=4;, score=0.787 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=10, min_samples_split=4;, score=0.841 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=10, min_samples_split=5;, score=0.779 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=10, min_samples_split=5;, score=0.846 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=10, min_samples_split=6;, score=0.768 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=10, min_samples_split=6;, score=0.831 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=10, min_samples_split=7;, score=0.784 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=10, min_samples_split=7;, score=0.831 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, min_samples_split=2;, score=0.768 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, min_samples_split=2;, score=0.833 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, min_samples_split=3;, score=0.785 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, min_samples_split=3;, score=0.841 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, min_samples_split=4;, score=0.782 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, min_samples_split=4;, score=0.828 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, min_samples_split=5;, score=0.781 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, min_samples_split=5;, score=0.823 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, min_samples_split=6;, score=0.789 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, min_samples_split=6;, score=0.826 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, min_samples_split=7;, score=0.784 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, min_samples_split=7;, score=0.834 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=1, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=1, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=1, min_samples_split=2;, score=0.199 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=1, min_samples_split=2;, score=0.199 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=1, min_samples_split=3;, score=0.199 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=1, min_samples_split=3;, score=0.199 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=1, min_samples_split=4;, score=0.199 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=1, min_samples_split=4;, score=0.199 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=1, min_samples_split=5;, score=0.199 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=1, min_samples_split=5;, score=0.199 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=1, min_samples_split=6;, score=0.199 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=1, min_samples_split=6;, score=0.199 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=1, min_samples_split=7;, score=0.199 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=1, min_samples_split=7;, score=0.199 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, min_samples_split=2;, score=0.701 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, min_samples_split=2;, score=0.815 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, min_samples_split=3;, score=0.712 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, min_samples_split=3;, score=0.814 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, min_samples_split=4;, score=0.709 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, min_samples_split=4;, score=0.811 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, min_samples_split=5;, score=0.704 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, min_samples_split=5;, score=0.820 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, min_samples_split=6;, score=0.700 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, min_samples_split=6;, score=0.811 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, min_samples_split=7;, score=0.711 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, min_samples_split=7;, score=0.820 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=6, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=6, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=6, min_samples_split=2;, score=0.747 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=6, min_samples_split=2;, score=0.823 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=6, min_samples_split=3;, score=0.755 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=6, min_samples_split=3;, score=0.825 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=6, min_samples_split=4;, score=0.741 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=6, min_samples_split=4;, score=0.831 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=6, min_samples_split=5;, score=0.749 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=6, min_samples_split=5;, score=0.818 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=6, min_samples_split=6;, score=0.750 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=6, min_samples_split=6;, score=0.831 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=6, min_samples_split=7;, score=0.739 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=6, min_samples_split=7;, score=0.830 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=7, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=7, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=7, min_samples_split=2;, score=0.773 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=7, min_samples_split=2;, score=0.847 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=7, min_samples_split=3;, score=0.776 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=7, min_samples_split=3;, score=0.831 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=7, min_samples_split=4;, score=0.774 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=7, min_samples_split=4;, score=0.839 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=7, min_samples_split=5;, score=0.768 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=7, min_samples_split=5;, score=0.828 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=7, min_samples_split=6;, score=0.762 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=7, min_samples_split=6;, score=0.839 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=7, min_samples_split=7;, score=0.776 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=7, min_samples_split=7;, score=0.834 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=8, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=8, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=8, min_samples_split=2;, score=0.801 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=8, min_samples_split=2;, score=0.842 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=8, min_samples_split=3;, score=0.779 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=8, min_samples_split=3;, score=0.844 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=8, min_samples_split=4;, score=0.779 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=8, min_samples_split=4;, score=0.836 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=8, min_samples_split=5;, score=0.792 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=8, min_samples_split=5;, score=0.826 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=8, min_samples_split=6;, score=0.776 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=8, min_samples_split=6;, score=0.841 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=8, min_samples_split=7;, score=0.790 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=8, min_samples_split=7;, score=0.838 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=9, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=9, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=9, min_samples_split=2;, score=0.779 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=9, min_samples_split=2;, score=0.822 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=9, min_samples_split=3;, score=0.789 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=9, min_samples_split=3;, score=0.833 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=9, min_samples_split=4;, score=0.776 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=9, min_samples_split=4;, score=0.833 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=9, min_samples_split=5;, score=0.795 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=9, min_samples_split=5;, score=0.842 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=9, min_samples_split=6;, score=0.787 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=9, min_samples_split=6;, score=0.826 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=9, min_samples_split=7;, score=0.779 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=9, min_samples_split=7;, score=0.823 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, min_samples_split=2;, score=0.712 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, min_samples_split=2;, score=0.814 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, min_samples_split=3;, score=0.715 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, min_samples_split=3;, score=0.817 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, min_samples_split=4;, score=0.712 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, min_samples_split=4;, score=0.823 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, min_samples_split=5;, score=0.712 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, min_samples_split=5;, score=0.820 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, min_samples_split=6;, score=0.703 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, min_samples_split=6;, score=0.812 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, min_samples_split=7;, score=0.714 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, min_samples_split=7;, score=0.815 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=10, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=10, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=10, min_samples_split=2;, score=0.771 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=10, min_samples_split=2;, score=0.838 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=10, min_samples_split=3;, score=0.779 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=10, min_samples_split=3;, score=0.828 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=10, min_samples_split=4;, score=0.774 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=10, min_samples_split=4;, score=0.836 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=10, min_samples_split=5;, score=0.771 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=10, min_samples_split=5;, score=0.820 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=10, min_samples_split=6;, score=0.779 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=10, min_samples_split=6;, score=0.842 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=10, min_samples_split=7;, score=0.774 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=10, min_samples_split=7;, score=0.826 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=15, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=15, min_samples_split=1;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=15, min_samples_split=2;, score=0.787 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=15, min_samples_split=2;, score=0.826 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=15, min_samples_split=3;, score=0.776 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=15, min_samples_split=3;, score=0.839 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=15, min_samples_split=4;, score=0.777 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=15, min_samples_split=4;, score=0.814 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=15, min_samples_split=5;, score=0.777 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=15, min_samples_split=5;, score=0.836 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=15, min_samples_split=6;, score=0.774 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=15, min_samples_split=6;, score=0.834 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=15, min_samples_split=7;, score=0.779 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=15, min_samples_split=7;, score=0.811 total time=   0.0s\n",
      "best parameter : DecisionTreeClassifier(criterion='log_loss', max_depth=8)\n",
      "test result :  0.8833333333333333\n"
     ]
    }
   ],
   "source": [
    "#30.Write a Python program to train a Decision Tree Classifier and use GridSearchCV to find the optimal values \n",
    "#for max_depth and min_samples_split.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param=({\n",
    "    \"criterion\":[\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_depth\":[1,5,6,7,8,9,5,10,15],\n",
    "    \"min_samples_split\":[1,2,3,4,5,6,7]\n",
    "})\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data=load_digits()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X=data.data\n",
    "y=data.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30,random_state=42)\n",
    "\n",
    "model=DecisionTreeClassifier()\n",
    "grid_model=GridSearchCV(model,param_grid=param,cv=2,verbose=5)\n",
    "\n",
    "grid_model.fit(X_train,y_train)\n",
    "\n",
    "print(f\"best parameter : {grid_model.best_estimator_}\")\n",
    "\n",
    "y_pred=grid_model.best_estimator_.predict(X_test)\n",
    "\n",
    "print(f\"test result :  {accuracy_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484ec916-9d20-472b-8dd9-cb30795de360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdca1e9-eac5-46e5-8c69-65f15207e5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed7cca9-5ad8-44fc-ae11-16fcef3c9183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f98fa13-9307-434f-a6ec-0abdeb9f3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#29.Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
