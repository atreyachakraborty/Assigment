{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8758aab-c47f-4a25-be48-07d6b7d22c4d",
   "metadata": {},
   "source": [
    "1. Can we use Bagging for regression problems?\n",
    "\n",
    "ANS. The technique involves training multiple regression models on different subsets of the training data and then averaging their predictions to make the final prediction.\n",
    "\n",
    "2. What is the difference between multiple model training and single model training?\n",
    "\n",
    "ANS. Single Model Training: This involves training one model on the entire dataset.\n",
    "Multiple Model Training: Involves training several models on different subsets or variations of the dataset, combining their predictions. This helps in reducing overfitting and improving performance.\n",
    "\n",
    "3. Explain the concept of feature randomness in Random Forest\n",
    "ANS.In Random Forest, feature randomness refers to randomly selecting a subset of features for each split in a decision tree. This helps in making the trees more diverse and reducing overfitting.\n",
    "\n",
    "\n",
    "4. What is OOB (Out-of-Bag) Score?\n",
    "ANS.The OOB Score is an estimate of the model’s performance. It is calculated by evaluating each tree in the forest on the samples that were not used during its training\n",
    "\n",
    "\n",
    "5. How can you measure the importance of features in a Random Forest model?\n",
    "ANS. Feature importance in Random Forest can be measured by calculating the decrease in impurity or the increase in prediction error when the feature is permuted. Common methods include Gini importance and Permutation importance.\n",
    "\n",
    "\n",
    "6. Explain the working principle of a Bagging Classifier?\n",
    "ANS. A Bagging Classifier works by creating multiple subsets of the original dataset using bootstrap sampling, training a base model on each subset, and combining the predictions of all base models (usually through voting or averaging).\n",
    "\n",
    "\n",
    "7. How do you evaluate a Bagging Classifier’s performance?\n",
    "ANS.Performance can be evaluated using metrics like accuracy, precision, recall, F1-score, or ROC-AUC for classification problems. Cross-validation and OOB score are also commonly used.\n",
    "\n",
    "\n",
    "8.How does a Bagging Regressor work?\n",
    "ANS. Bagging Regressor works similarly to a Bagging Classifier but is used for regression problems. It creates multiple subsets of the dataset using bootstrap sampling, trains a regression model on each subset, and averages the predictions of all models.\n",
    "\n",
    "\n",
    "9.What is the main advantage of ensemble techniques?\n",
    "ANS. The main advantage is the improved performance through variance reduction, increased robustness, and better generalization compared to individual models.\n",
    "\n",
    "\n",
    "10. What is the main challenge of ensemble methods?\n",
    "ANS.The main challenge is increased computational complexity and training time due to the need to train multiple models.\n",
    "\n",
    "11. Explain the key idea behind ensemble techniques?\n",
    "ANS. The key idea is to combine the predictions of multiple models to produce a more accurate and robust prediction. This can be achieved through techniques like Bagging, Boosting, and Stacking\n",
    "\n",
    "\n",
    "12. What is a Random Forest Classifier?\n",
    "ANS. A Random Forest Classifier is an ensemble learning method that constructs multiple decision trees during training and outputs the mode of the classes for classification tasks.\n",
    "\n",
    "\n",
    "13. What are the main types of ensemble techniques?\n",
    "ANS.Bagging (Bootstrap Aggregating)\n",
    "Boosting (e.g., AdaBoost, Gradient Boosting)\n",
    "Stacking (Stacked Generalization)\n",
    "\n",
    "\n",
    "14. What is ensemble learning in machine learning?\n",
    "ANS. Ensemble learning is a technique that combines multiple individual models (learners) to produce a single, stronger model that improves the overall performance and robustness.\n",
    "\n",
    "\n",
    "15. When should we avoid using ensemble methods?\n",
    "ANS. Assembly methods may not be suitable when:\n",
    "Computing resources are limited.\n",
    "Interpretability of the model is crucial.\n",
    "The base model alone provides sufficient performance.\n",
    "\n",
    "\n",
    "16. How does bagging help in reducing overfitting?\n",
    "ANS. Bagging reduces overfitting by training multiple models on different subsets of the data, thereby reducing the variance and making the ensemble less sensitive to noise in the training data.\n",
    "\n",
    "\n",
    "17. Why is Random Forest better than a single Decision Tree?\n",
    "ANS. Random Forest is better because it reduces overfitting by averaging multiple decision trees, increasing robustness and improving generalization to unseen data.\n",
    "\n",
    "\n",
    "18. What is the role of bootstrap sampling in Bagging?\n",
    "ANS. Bootstrap sampling involves randomly selecting subsets of data with replacement to create multiple training sets. This ensures diversity among the models and helps reduce overfitting.\n",
    "\n",
    "\n",
    "19. What are some real-world applications of ensemble techniques?\n",
    "ANS. Fraud detection\n",
    "Medical diagnosis\n",
    "Stock market prediction\n",
    "Recommendation systems\n",
    "Sentiment analysis\n",
    "\n",
    "\n",
    "20. What is the difference between Bagging and Boosting?\n",
    "\n",
    "Bagging: Reduces variance by training models in parallel on different subsets of the data and averaging their predictions.\n",
    "Boosting: Reduces bias by training models sequentially, where each model attempts to correct the errors of the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f63cbb-94fe-4a2b-a48b-2bc64d6eb9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36d1ca-e066-4baa-9f3b-056f7fa33b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e2b4d83-86bd-49bd-8783-19f00c82d7a1",
   "metadata": {},
   "source": [
    "# ---------------------- Practical ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ee9ce5c-8326-4715-a41f-a5fc954f630b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data=load_breast_cancer()\n",
    "X,y=data.data,data.target\n",
    "X\n",
    "y\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "clf=BaggingClassifier(estimator=DecisionTreeClassifier())\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf89c0-3bee-484b-ba57-1dcf8984093f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201fa342-614a-4ec6-bc7d-bbc6a4dbf51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ae871f-1326-4970-83fa-64352ab5666d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7851780585913783"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "data=fetch_california_housing()\n",
    "X,y=data.data,data.target\n",
    "X\n",
    "y\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "clf=BaggingRegressor(estimator=DecisionTreeRegressor())\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c32dc-b6f1-4adb-abb0-2591cf4c5f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc42dc9-bb73-4a4d-a64c-8b56e541cae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae1957f8-e2ca-4525-8ccd-7968d5288d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#23.Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data=load_breast_cancer()\n",
    "#print(data)\n",
    "\n",
    "X,y=data.data,data.target\n",
    "X\n",
    "y\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "\n",
    "clf=RandomForestClassifier( min_samples_split=4,oob_score=True)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ed36a-c01c-41d6-b78a-7b2449b8b037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f61574b-ca1b-47e2-970a-9193089d267b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19479f20-fb3b-49db-b6be-43dbb5a5e9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " r2 score for randomforest 0.8047604106733843\n",
      "r2 score for decision tree 0.6026890860464447\n"
     ]
    }
   ],
   "source": [
    "# 24.Train a Random Forest Regressor and compare its performance with a single Decision Tree\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "data=fetch_california_housing()\n",
    "X,y=data.data,data.target\n",
    "X\n",
    "y\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "reg_model1=RandomForestRegressor()\n",
    "reg_model1.fit(X_train,y_train)\n",
    "dt_model=DecisionTreeRegressor()\n",
    "dt_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred=reg_model1.predict(X_test)\n",
    "y_pred2=dt_model.predict(X_test)\n",
    "\n",
    "print(f\" r2 score for randomforest {r2_score(y_test,y_pred)}\")\n",
    "print(f\"r2 score for decision tree {r2_score(y_test,y_pred2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064d944-057a-421f-9e55-725e6d649d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138e1970-e5a1-436b-a279-bc932a21d259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5e660-7ef4-4312-b14a-bc1df0b7bb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b896787-5ee6-4319-a4f3-ee3f1575cb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data=load_breast_cancer()\n",
    "#print(data)\n",
    "\n",
    "X,y=data.data,data.target\n",
    "X\n",
    "y\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "\n",
    "clf=RandomForestClassifier( min_samples_split=4,oob_score=True)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "clf.oob_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f27109-09a8-4cc6-b9a3-f3a258750b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4202a8-e8cc-4cf0-8406-29d7633363ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b5c945-25af-4b6e-ab48-d70392c37c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f0bfbe-12f9-47ab-9ed2-0978808ecad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#26.  Train a Bagging Classifier using SVM as a base estimator and print accuracy\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data=load_breast_cancer()\n",
    "X,y=data.data,data.target\n",
    "X\n",
    "y\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "clf=BaggingClassifier(estimator=SVC())\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3f814b-fa11-4dfb-97c9-30b1660fd5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ccd46-09f7-4fdb-ad49-127793cfa7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b2232-a3c3-4a58-9b2d-9d118e2074a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9403c2d6-1f61-4523-814b-61ff26758c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the accuracy of standard random forest 0.9707602339181286\n",
      " the accuracy of s random forest model 2 0.9707602339181286\n"
     ]
    }
   ],
   "source": [
    "#27. Train a Random Forest Classifier with different numbers of trees and compare accuracy\n",
    "\n",
    "data=load_breast_cancer()\n",
    "#print(data)\n",
    "\n",
    "X,y=data.data,data.target\n",
    "X\n",
    "y\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "\n",
    "rfc1=RandomForestClassifier( min_samples_split=4,oob_score=True)\n",
    "rfc1.fit(X_train,y_train)\n",
    "y_pred=rfc1.predict(X_test)\n",
    "\n",
    "print(f\" the accuracy of standard random forest {accuracy_score(y_test,y_pred)}\")\n",
    "\n",
    "rfc2=RandomForestClassifier(n_estimators=60, min_samples_split=4,max_features=\"log2\")\n",
    "rfc2.fit(X_train,y_train)\n",
    "y_pred2=rfc2.predict(X_test)\n",
    "print(f\" the accuracy of s random forest model 2 {accuracy_score(y_test,y_pred2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34749f0d-b752-4c39-b626-1bf475040de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650a023f-7ec7-45c6-81b3-86da8a025287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32facacc-d0d2-4422-86f6-7fe60a9ebb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6876b6ce-2e34-4ccb-976b-e24ef2e9c9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data=load_breast_cancer()\n",
    "X,y=data.data,data.target\n",
    "X\n",
    "y\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "clf=BaggingClassifier(estimator=LogisticRegression())\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03ba39-6555-40aa-8754-47f1860f85cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd83b75-9304-4e4e-83e4-c567b11068e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32be458b-d127-4291-a6b8-ad5146c55225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " r2 score for randomforest 0.4678921839795316\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature name</th>\n",
       "      <th>feature importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.011496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>s4</td>\n",
       "      <td>0.026382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s1</td>\n",
       "      <td>0.055157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s2</td>\n",
       "      <td>0.056618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s3</td>\n",
       "      <td>0.059810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s6</td>\n",
       "      <td>0.063245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.063819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bp</td>\n",
       "      <td>0.102866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>s5</td>\n",
       "      <td>0.182296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bmi</td>\n",
       "      <td>0.378311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature name  feature importance\n",
       "1          sex            0.011496\n",
       "7           s4            0.026382\n",
       "4           s1            0.055157\n",
       "5           s2            0.056618\n",
       "6           s3            0.059810\n",
       "9           s6            0.063245\n",
       "0          age            0.063819\n",
       "3           bp            0.102866\n",
       "8           s5            0.182296\n",
       "2          bmi            0.378311"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#29. Train a Random Forest Regressor and analyze feature importance scores\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "data=load_diabetes()\n",
    "X,y=data.data,data.target\n",
    "X\n",
    "y\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "reg_model1=RandomForestRegressor()\n",
    "reg_model1.fit(X_train,y_train)\n",
    "y_pred=reg_model1.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\" r2 score for randomforest {r2_score(y_test,y_pred)}\")\n",
    "\n",
    "feature_importance=reg_model1.feature_importances_\n",
    "feature_names=data.feature_names\n",
    "\n",
    "df=pd.DataFrame({\"feature name\":feature_names,\"feature importance\":feature_importance})\n",
    "df=df.sort_values(by=\"feature importance\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55101f2c-3276-4347-a416-952f5e30f08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73915f-3cff-442d-971c-ef318c37aeff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85e9678-2c1a-442c-a05c-dceaad3b727e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 0.937037037037037\n",
      "Random Forest Classifier Accuracy: 0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "#30. Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "iris = load_digits()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "bagging_clf = BaggingClassifier()\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "random_forest_clf = RandomForestClassifier()\n",
    "random_forest_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_bagging = bagging_clf.predict(X_test)\n",
    "y_pred_rf = random_forest_clf.predict(X_test)\n",
    "\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Bagging Classifier Accuracy: {accuracy_bagging}\")\n",
    "print(f\"Random Forest Classifier Accuracy: {accuracy_rf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e180481-7f33-419f-bd8d-53b11b20ec46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f2b14-f2de-4d60-b836-a6883b477941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a237643-f9e0-4a18-89eb-3e311d608d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 144 candidates, totalling 288 fits\n",
      "[CV 1/2] END criterion=gini, max_depth=5, n_estimators=100;, score=0.919 total time=   0.3s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, n_estimators=100;, score=0.938 total time=   0.3s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, n_estimators=200;, score=0.925 total time=   0.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, n_estimators=200;, score=0.954 total time=   0.9s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, n_estimators=500;, score=0.930 total time=   1.8s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, n_estimators=500;, score=0.947 total time=   1.3s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, n_estimators=50;, score=0.916 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, n_estimators=50;, score=0.933 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, n_estimators=60;, score=0.914 total time=   0.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, n_estimators=60;, score=0.938 total time=   0.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, n_estimators=40;, score=0.913 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, n_estimators=40;, score=0.916 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=5, n_estimators=30;, score=0.892 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=5, n_estimators=30;, score=0.938 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, n_estimators=100;, score=0.936 total time=   0.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, n_estimators=100;, score=0.967 total time=   0.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, n_estimators=200;, score=0.943 total time=   0.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, n_estimators=200;, score=0.967 total time=   0.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, n_estimators=500;, score=0.943 total time=   1.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, n_estimators=500;, score=0.970 total time=   1.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, n_estimators=50;, score=0.932 total time=   0.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, n_estimators=50;, score=0.965 total time=   0.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, n_estimators=60;, score=0.928 total time=   0.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, n_estimators=60;, score=0.959 total time=   0.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, n_estimators=40;, score=0.940 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, n_estimators=40;, score=0.962 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=7, n_estimators=30;, score=0.935 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=7, n_estimators=30;, score=0.939 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=10, n_estimators=100;, score=0.943 total time=   0.3s\n",
      "[CV 2/2] END criterion=gini, max_depth=10, n_estimators=100;, score=0.968 total time=   0.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=10, n_estimators=200;, score=0.952 total time=   0.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=10, n_estimators=200;, score=0.968 total time=   0.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=10, n_estimators=500;, score=0.944 total time=   1.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=10, n_estimators=500;, score=0.975 total time=   1.7s\n",
      "[CV 1/2] END criterion=gini, max_depth=10, n_estimators=50;, score=0.943 total time=   0.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=10, n_estimators=50;, score=0.965 total time=   0.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=10, n_estimators=60;, score=0.941 total time=   0.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=10, n_estimators=60;, score=0.965 total time=   0.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=10, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=10, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=10, n_estimators=40;, score=0.930 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=10, n_estimators=40;, score=0.963 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=10, n_estimators=30;, score=0.948 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=10, n_estimators=30;, score=0.952 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, n_estimators=100;, score=0.946 total time=   0.3s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, n_estimators=100;, score=0.978 total time=   0.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, n_estimators=200;, score=0.944 total time=   0.6s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, n_estimators=200;, score=0.970 total time=   0.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, n_estimators=500;, score=0.944 total time=   1.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, n_estimators=500;, score=0.976 total time=   1.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, n_estimators=50;, score=0.948 total time=   0.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, n_estimators=50;, score=0.965 total time=   0.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, n_estimators=60;, score=0.946 total time=   0.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, n_estimators=60;, score=0.973 total time=   0.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, n_estimators=40;, score=0.941 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, n_estimators=40;, score=0.960 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=15, n_estimators=30;, score=0.938 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=15, n_estimators=30;, score=0.973 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=12, n_estimators=100;, score=0.948 total time=   0.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=12, n_estimators=100;, score=0.962 total time=   0.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=12, n_estimators=200;, score=0.948 total time=   0.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=12, n_estimators=200;, score=0.975 total time=   0.6s\n",
      "[CV 1/2] END criterion=gini, max_depth=12, n_estimators=500;, score=0.946 total time=   1.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=12, n_estimators=500;, score=0.976 total time=   1.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=12, n_estimators=50;, score=0.948 total time=   0.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=12, n_estimators=50;, score=0.978 total time=   0.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=12, n_estimators=60;, score=0.951 total time=   0.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=12, n_estimators=60;, score=0.963 total time=   0.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=12, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=12, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=12, n_estimators=40;, score=0.952 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=12, n_estimators=40;, score=0.960 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=12, n_estimators=30;, score=0.935 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=12, n_estimators=30;, score=0.959 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=17, n_estimators=100;, score=0.943 total time=   0.2s\n",
      "[CV 2/2] END criterion=gini, max_depth=17, n_estimators=100;, score=0.971 total time=   0.2s\n",
      "[CV 1/2] END criterion=gini, max_depth=17, n_estimators=200;, score=0.944 total time=   0.5s\n",
      "[CV 2/2] END criterion=gini, max_depth=17, n_estimators=200;, score=0.975 total time=   0.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=17, n_estimators=500;, score=0.944 total time=   1.4s\n",
      "[CV 2/2] END criterion=gini, max_depth=17, n_estimators=500;, score=0.978 total time=   1.5s\n",
      "[CV 1/2] END criterion=gini, max_depth=17, n_estimators=50;, score=0.952 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=17, n_estimators=50;, score=0.963 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=17, n_estimators=60;, score=0.941 total time=   0.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=17, n_estimators=60;, score=0.970 total time=   0.1s\n",
      "[CV 1/2] END criterion=gini, max_depth=17, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=17, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=17, n_estimators=40;, score=0.935 total time=   0.1s\n",
      "[CV 2/2] END criterion=gini, max_depth=17, n_estimators=40;, score=0.962 total time=   0.0s\n",
      "[CV 1/2] END criterion=gini, max_depth=17, n_estimators=30;, score=0.927 total time=   0.0s\n",
      "[CV 2/2] END criterion=gini, max_depth=17, n_estimators=30;, score=0.959 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, n_estimators=100;, score=0.916 total time=   0.2s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, n_estimators=100;, score=0.949 total time=   0.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, n_estimators=200;, score=0.924 total time=   0.5s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, n_estimators=200;, score=0.954 total time=   0.5s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, n_estimators=500;, score=0.922 total time=   1.4s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, n_estimators=500;, score=0.960 total time=   1.4s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, n_estimators=50;, score=0.908 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, n_estimators=50;, score=0.949 total time=   0.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, n_estimators=60;, score=0.927 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, n_estimators=60;, score=0.951 total time=   0.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, n_estimators=40;, score=0.924 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, n_estimators=40;, score=0.947 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=5, n_estimators=30;, score=0.917 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=5, n_estimators=30;, score=0.936 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, n_estimators=100;, score=0.941 total time=   0.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, n_estimators=100;, score=0.973 total time=   0.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, n_estimators=200;, score=0.949 total time=   0.6s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, n_estimators=200;, score=0.971 total time=   0.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, n_estimators=500;, score=0.951 total time=   1.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, n_estimators=500;, score=0.973 total time=   1.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, n_estimators=50;, score=0.935 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, n_estimators=50;, score=0.967 total time=   0.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, n_estimators=60;, score=0.938 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, n_estimators=60;, score=0.954 total time=   0.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, n_estimators=40;, score=0.935 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, n_estimators=40;, score=0.960 total time=   0.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=7, n_estimators=30;, score=0.933 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=7, n_estimators=30;, score=0.951 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=10, n_estimators=100;, score=0.949 total time=   0.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=10, n_estimators=100;, score=0.967 total time=   0.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=10, n_estimators=200;, score=0.944 total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=10, n_estimators=200;, score=0.968 total time=   0.6s\n",
      "[CV 1/2] END criterion=entropy, max_depth=10, n_estimators=500;, score=0.951 total time=   1.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=10, n_estimators=500;, score=0.976 total time=   1.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=10, n_estimators=50;, score=0.930 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=10, n_estimators=50;, score=0.967 total time=   0.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=10, n_estimators=60;, score=0.943 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=10, n_estimators=60;, score=0.960 total time=   0.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=10, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=10, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=10, n_estimators=40;, score=0.935 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=10, n_estimators=40;, score=0.959 total time=   0.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=10, n_estimators=30;, score=0.936 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=10, n_estimators=30;, score=0.957 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, n_estimators=100;, score=0.955 total time=   0.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, n_estimators=100;, score=0.965 total time=   0.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, n_estimators=200;, score=0.948 total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, n_estimators=200;, score=0.978 total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, n_estimators=500;, score=0.952 total time=   1.9s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, n_estimators=500;, score=0.978 total time=   1.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, n_estimators=50;, score=0.944 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, n_estimators=50;, score=0.968 total time=   0.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, n_estimators=60;, score=0.948 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, n_estimators=60;, score=0.970 total time=   0.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, n_estimators=40;, score=0.946 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, n_estimators=40;, score=0.954 total time=   0.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=15, n_estimators=30;, score=0.941 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=15, n_estimators=30;, score=0.957 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=12, n_estimators=100;, score=0.936 total time=   0.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=12, n_estimators=100;, score=0.970 total time=   0.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=12, n_estimators=200;, score=0.954 total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=12, n_estimators=200;, score=0.973 total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=12, n_estimators=500;, score=0.948 total time=   1.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=12, n_estimators=500;, score=0.970 total time=   1.8s\n",
      "[CV 1/2] END criterion=entropy, max_depth=12, n_estimators=50;, score=0.948 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=12, n_estimators=50;, score=0.957 total time=   0.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=12, n_estimators=60;, score=0.949 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=12, n_estimators=60;, score=0.967 total time=   0.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=12, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=12, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=12, n_estimators=40;, score=0.940 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=12, n_estimators=40;, score=0.957 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=12, n_estimators=30;, score=0.940 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=12, n_estimators=30;, score=0.954 total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=17, n_estimators=100;, score=0.940 total time=   0.3s\n",
      "[CV 2/2] END criterion=entropy, max_depth=17, n_estimators=100;, score=0.971 total time=   0.3s\n",
      "[CV 1/2] END criterion=entropy, max_depth=17, n_estimators=200;, score=0.952 total time=   0.7s\n",
      "[CV 2/2] END criterion=entropy, max_depth=17, n_estimators=200;, score=0.973 total time=   0.7s\n",
      "[CV 1/2] END criterion=entropy, max_depth=17, n_estimators=500;, score=0.948 total time=   1.8s\n",
      "[CV 2/2] END criterion=entropy, max_depth=17, n_estimators=500;, score=0.973 total time=   1.9s\n",
      "[CV 1/2] END criterion=entropy, max_depth=17, n_estimators=50;, score=0.944 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=17, n_estimators=50;, score=0.970 total time=   0.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=17, n_estimators=60;, score=0.932 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=17, n_estimators=60;, score=0.965 total time=   0.2s\n",
      "[CV 1/2] END criterion=entropy, max_depth=17, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=17, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=entropy, max_depth=17, n_estimators=40;, score=0.940 total time=   0.1s\n",
      "[CV 2/2] END criterion=entropy, max_depth=17, n_estimators=40;, score=0.975 total time=   0.1s\n",
      "[CV 1/2] END criterion=entropy, max_depth=17, n_estimators=30;, score=0.935 total time=   0.0s\n",
      "[CV 2/2] END criterion=entropy, max_depth=17, n_estimators=30;, score=0.979 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, n_estimators=100;, score=0.922 total time=   0.2s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, n_estimators=100;, score=0.947 total time=   0.2s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, n_estimators=200;, score=0.922 total time=   0.5s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, n_estimators=200;, score=0.951 total time=   0.5s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, n_estimators=500;, score=0.933 total time=   1.5s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, n_estimators=500;, score=0.957 total time=   1.5s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, n_estimators=50;, score=0.916 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, n_estimators=50;, score=0.944 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, n_estimators=60;, score=0.922 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, n_estimators=60;, score=0.938 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, n_estimators=40;, score=0.905 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, n_estimators=40;, score=0.938 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=5, n_estimators=30;, score=0.903 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=5, n_estimators=30;, score=0.939 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=7, n_estimators=100;, score=0.952 total time=   0.3s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=7, n_estimators=100;, score=0.957 total time=   0.3s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=7, n_estimators=200;, score=0.944 total time=   0.6s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=7, n_estimators=200;, score=0.962 total time=   0.6s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=7, n_estimators=500;, score=0.946 total time=   1.8s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=7, n_estimators=500;, score=0.967 total time=   1.8s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=7, n_estimators=50;, score=0.930 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=7, n_estimators=50;, score=0.959 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=7, n_estimators=60;, score=0.944 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=7, n_estimators=60;, score=0.959 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=7, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=7, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=7, n_estimators=40;, score=0.932 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=7, n_estimators=40;, score=0.955 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=7, n_estimators=30;, score=0.933 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=7, n_estimators=30;, score=0.955 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=10, n_estimators=100;, score=0.949 total time=   0.3s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=10, n_estimators=100;, score=0.965 total time=   0.3s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=10, n_estimators=200;, score=0.954 total time=   0.7s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=10, n_estimators=200;, score=0.967 total time=   0.7s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=10, n_estimators=500;, score=0.946 total time=   1.8s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=10, n_estimators=500;, score=0.976 total time=   1.9s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=10, n_estimators=50;, score=0.935 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=10, n_estimators=50;, score=0.965 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=10, n_estimators=60;, score=0.941 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=10, n_estimators=60;, score=0.963 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=10, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=10, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=10, n_estimators=40;, score=0.933 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=10, n_estimators=40;, score=0.960 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=10, n_estimators=30;, score=0.932 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=10, n_estimators=30;, score=0.947 total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=15, n_estimators=100;, score=0.940 total time=   0.3s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=15, n_estimators=100;, score=0.975 total time=   0.3s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=15, n_estimators=200;, score=0.948 total time=   0.7s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=15, n_estimators=200;, score=0.970 total time=   0.7s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=15, n_estimators=500;, score=0.951 total time=   1.8s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=15, n_estimators=500;, score=0.975 total time=   2.2s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=15, n_estimators=50;, score=0.940 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=15, n_estimators=50;, score=0.967 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=15, n_estimators=60;, score=0.951 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=15, n_estimators=60;, score=0.960 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=15, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=15, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=15, n_estimators=40;, score=0.932 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=15, n_estimators=40;, score=0.963 total time=   0.2s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=15, n_estimators=30;, score=0.944 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=15, n_estimators=30;, score=0.965 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=12, n_estimators=100;, score=0.941 total time=   0.9s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=12, n_estimators=100;, score=0.957 total time=   0.6s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=12, n_estimators=200;, score=0.949 total time=   0.9s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=12, n_estimators=200;, score=0.976 total time=   0.7s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=12, n_estimators=500;, score=0.954 total time=   2.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=12, n_estimators=500;, score=0.973 total time=   2.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=12, n_estimators=50;, score=0.946 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=12, n_estimators=50;, score=0.962 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=12, n_estimators=60;, score=0.944 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=12, n_estimators=60;, score=0.971 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=12, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=12, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=12, n_estimators=40;, score=0.944 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=12, n_estimators=40;, score=0.970 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=12, n_estimators=30;, score=0.943 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=12, n_estimators=30;, score=0.955 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=17, n_estimators=100;, score=0.948 total time=   0.4s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=17, n_estimators=100;, score=0.971 total time=   0.4s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=17, n_estimators=200;, score=0.948 total time=   1.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=17, n_estimators=200;, score=0.965 total time=   1.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=17, n_estimators=500;, score=0.949 total time=   2.6s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=17, n_estimators=500;, score=0.975 total time=   2.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=17, n_estimators=50;, score=0.936 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=17, n_estimators=50;, score=0.959 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=17, n_estimators=60;, score=0.938 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=17, n_estimators=60;, score=0.963 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=17, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=17, n_estimators=0;, score=nan total time=   0.0s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=17, n_estimators=40;, score=0.946 total time=   0.1s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=17, n_estimators=40;, score=0.965 total time=   0.1s\n",
      "[CV 1/2] END criterion=log_loss, max_depth=17, n_estimators=30;, score=0.938 total time=   0.0s\n",
      "[CV 2/2] END criterion=log_loss, max_depth=17, n_estimators=30;, score=0.962 total time=   0.0s\n",
      "Bagging Classifier Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "#31.Train a Random Forest Classifier and tune hyperparameters using GridSearchCV?\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf=RandomForestClassifier()\n",
    "iris = load_digits()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param={\"max_depth\":[5,7,10,15,12,17],\n",
    "      \"n_estimators\":[100,200,500,50,60,0,40,30],\n",
    "       \"criterion\":[\"gini\", \"entropy\", \"log_loss\"]}\n",
    "\n",
    "model=GridSearchCV(clf,param_grid=param,cv=2,verbose=5)\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "\n",
    "print(f\"Bagging Classifier Accuracy: {accuracy}\")\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66ebe507-98d8-4c62-b132-94c7cd940ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=15, n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=15, n_estimators=500)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=15, n_estimators=500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7267f854-fe00-4ea5-a673-326be3f99e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a9900-ab42-407d-a53a-fd7a6832ef92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed17c638-2bed-4310-9952-d5468c51ace2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "397d0ca4-b198-4c0a-9f50-186dda8e36c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#32. Train a Bagging Regressor with different numbers of base estimators and compare performance\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "n_estimators_list = [1, 10, 50, 100, 200]\n",
    "mse_list = []\n",
    "\n",
    "# Initialize the Bagging Regressor with DecisionTreeRegressor as the base estimator\n",
    "for n_estimators in n_estimators_list: \n",
    "    model = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=n_estimators, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list.append(mse)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(n_estimators_list, mse_list, marker='o')\n",
    "plt.xlabel('Number of Base Estimators')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Performance of Bagging Regressor with Different Numbers of Base Estimators')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b78568-2c76-44b7-afd1-35ea671abdb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c23bbf1-0fd0-4c8e-94a4-d2dd1f0232cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5408e014-9830-4181-9609-2534d815e089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96        63\n",
      "           1       0.96      0.99      0.98       108\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.96      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n",
      "[[ 59   4]\n",
      " [  1 107]]\n",
      "Misclassified Samples:\n",
      "[[1.334e+01 1.586e+01 8.649e+01 5.200e+02 1.078e-01 1.535e-01 1.169e-01\n",
      "  6.987e-02 1.942e-01 6.902e-02 2.860e-01 1.016e+00 1.535e+00 1.296e+01\n",
      "  6.794e-03 3.575e-02 3.980e-02 1.383e-02 2.134e-02 4.603e-03 1.553e+01\n",
      "  2.319e+01 9.666e+01 6.149e+02 1.536e-01 4.791e-01 4.858e-01 1.708e-01\n",
      "  3.527e-01 1.016e-01]\n",
      " [1.380e+01 1.579e+01 9.043e+01 5.841e+02 1.007e-01 1.280e-01 7.789e-02\n",
      "  5.069e-02 1.662e-01 6.566e-02 2.787e-01 6.205e-01 1.957e+00 2.335e+01\n",
      "  4.717e-03 2.065e-02 1.759e-02 9.206e-03 1.220e-02 3.130e-03 1.657e+01\n",
      "  2.086e+01 1.103e+02 8.124e+02 1.411e-01 3.542e-01 2.779e-01 1.383e-01\n",
      "  2.589e-01 1.030e-01]\n",
      " [1.396e+01 1.705e+01 9.143e+01 6.024e+02 1.096e-01 1.279e-01 9.789e-02\n",
      "  5.246e-02 1.908e-01 6.130e-02 4.250e-01 8.098e-01 2.563e+00 3.574e+01\n",
      "  6.351e-03 2.679e-02 3.119e-02 1.342e-02 2.062e-02 2.695e-03 1.639e+01\n",
      "  2.207e+01 1.081e+02 8.260e+02 1.512e-01 3.262e-01 3.209e-01 1.374e-01\n",
      "  3.068e-01 7.957e-02]\n",
      " [1.448e+01 2.146e+01 9.425e+01 6.482e+02 9.444e-02 9.947e-02 1.204e-01\n",
      "  4.938e-02 2.075e-01 5.636e-02 4.204e-01 2.220e+00 3.301e+00 3.887e+01\n",
      "  9.369e-03 2.983e-02 5.371e-02 1.761e-02 2.418e-02 3.249e-03 1.621e+01\n",
      "  2.925e+01 1.084e+02 8.089e+02 1.306e-01 1.976e-01 3.349e-01 1.225e-01\n",
      "  3.020e-01 6.846e-02]\n",
      " [1.513e+01 2.981e+01 9.671e+01 7.195e+02 8.320e-02 4.605e-02 4.686e-02\n",
      "  2.739e-02 1.852e-01 5.294e-02 4.681e-01 1.627e+00 3.043e+00 4.538e+01\n",
      "  6.831e-03 1.427e-02 2.489e-02 9.087e-03 3.151e-02 1.750e-03 1.726e+01\n",
      "  3.691e+01 1.101e+02 9.314e+02 1.148e-01 9.866e-02 1.547e-01 6.575e-02\n",
      "  3.233e-01 6.165e-02]]\n"
     ]
    }
   ],
   "source": [
    "#33.Train a Random Forest Classifier and analyze misclassified samples \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "iris = load_breast_cancer()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Identify misclassified samples\n",
    "misclassified_samples = X_test[y_test != y_pred]\n",
    "print(\"Misclassified Samples:\")\n",
    "print(misclassified_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1074d5e-7eb4-4368-b8d9-78dadd596eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd6032-8d82-42f1-9b1f-225cbc03615e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cbdbff17-de87-44a6-b073-1fe5622d6571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (DecisionTree): 0.2885716163522112\n",
      "Mean Squared Error (KNeighbors): 1.1228861439830626\n"
     ]
    }
   ],
   "source": [
    "#40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare \n",
    "#performance\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "boston = fetch_california_housing()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "\n",
    "bagging_dt = BaggingRegressor(estimator=dt)\n",
    "bagging_dt.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "bagging_knn = BaggingRegressor(estimator=knn)\n",
    "bagging_knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = bagging_dt.predict(X_test)\n",
    "y_pred_knn = bagging_knn.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"Mean Squared Error (DecisionTree): {mse_dt}\")\n",
    "print(f\"Mean Squared Error (KNeighbors): {mse_knn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eff44c-f59c-4ed7-a5bf-a7d85c7ead84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e91cdfb-351b-4720-999c-27da5c883f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abc35e4e-c0bb-48ef-8aba-c61403f10fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.967) total time=   0.3s\n",
      "[CV] END ................................ score: (test=0.967) total time=   0.3s\n",
      "[CV] END ................................ score: (test=0.900) total time=   0.3s\n",
      "[CV] END ................................ score: (test=0.967) total time=   0.3s\n",
      "[CV] END ................................ score: (test=1.000) total time=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.9       , 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#42  Train a Bagging Classifier and evaluate its performance using cross-validation\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance using cross-validation\n",
    "cross_val_score(bagging_clf, X, y, cv=5,verbose=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6103bc8f-849a-4865-874e-b419eff4cdd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e8d04de6-96c6-4d92-a85d-e8eda3a01ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap samples: 0.5, Mean Squared Error: 2748.3134203007517\n",
      "Bootstrap samples: 0.7, Mean Squared Error: 2768.270886466166\n",
      "Bootstrap samples: 1.0, Mean Squared Error: 2908.80615037594\n"
     ]
    }
   ],
   "source": [
    "#45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data = load_diabetes()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "bootstrap_samples = [0.5, 0.7, 1.0]\n",
    "\n",
    "mse_scores = []\n",
    "\n",
    "for bs in bootstrap_samples:\n",
    "    # Train Bagging Regressor with different levels of bootstrap samples\n",
    "    bagging_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=100, max_samples=bs, random_state=42)\n",
    "    bagging_reg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = bagging_reg.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "    print(f\"Bootstrap samples: {bs}, Mean Squared Error: {mse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c292be2-daa5-419d-8edb-77c80c5664d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
